# llm_host.py 业务逻辑分析

`llm_host.py` 文件定义了一个名为 `ForumHost` 的核心类，其主要职责是扮演一个智能的“论坛主持人”。这个主持人的目标是引导和协调项目中其他几个 AI 智能体（Agent）的讨论，使它们的分析过程更有深度和方向性。

### 1. **核心功能与定位**

- **智能中介**: `ForumHost` 不直接参与原始数据分析，而是作为 `INSIGHT`、`MEDIA`、`QUERY` 这三个 Agent 的“上层协调者”。
- **引导讨论**: 它的核心任务是读取并理解各个 Agent 的分析结果（记录在 `forum.log` 中），然后生成一段综合性的、具有引导性的发言，以推动整个分析流程向更深层次发展。

### 2. **技术实现**

- **大语言模型 (LLM) 驱动**: `ForumHost` 的智能来自于一个强大的外部大语言模型（LLM），具体配置为使用“硅基流动”(SiliconFlow) 提供的 `Qwen3` 模型。
- **API 交互**: 它通过一个兼容 OpenAI 标准的 API 接口与该 LLM 进行通信。相关的 API 密钥和地址等配置信息从项目的主配置文件 (`config.py`) 中动态加载。

### 3. **工作流程**

`ForumHost` 生成一次发言的完整流程如下：

1.  **输入日志**: 接收一个包含多行 `forum.log` 内容的列表作为输入。
2.  **日志解析 (`_parse_forum_logs`)**:
    - 遍历输入的日志行，使用正则表达式精确提取出由 `INSIGHT`、`MEDIA`、`QUERY` 这三个 Agent 产生的有效发言。
    - 自动过滤掉系统消息（`SYSTEM`）和主持人自己之前（`HOST`）的发言，避免信息干扰。
3.  **提示词工程 (Prompt Engineering)**: 这是实现其智能的关键步骤。它会精心构建两个不同的提示（Prompt）发送给 LLM：
    - **系统提示 (`_build_system_prompt`)**: 这个提示为 LLM 设定了其角色和行为准则。它告诉 LLM：“你是一个多 agent 舆情分析系统的论坛主持人”，并详细定义了主持人的六大职责：事件梳理、引导讨论、纠正错误、整合观点、趋势预测和推进分析。同时，它还向 LLM 介绍了其他三个 Agent 各自的专长，帮助 LLM 更好地理解上下文。
    - **用户提示 (`_build_user_prompt`)**: 这个提示包含了从日志中解析出的、各个 Agent 最近的实际发言内容。然后，它给 LLM 下达了一个明确的任务指令：要求其生成的发言必须包含四个结构清晰的部分：事件梳理、观点整合、深层分析和问题引导。
4.  **调用 LLM API (`_call_qwen_api`)**:
    - 将上述构建好的两个提示发送给 `Qwen` 模型。
    - 该调用被一个装饰器 `@with_graceful_retry` 所包裹，这意味着如果 API 调用因为网络等问题临时失败，程序会自动进行重试，增强了系统的健壮性。
5.  **格式化输出 (`_format_host_speech`)**:
    - 对 LLM 返回的原始文本进行清理，例如移除多余的空行和不必要的引号，使输出内容更加整洁规范。
6.  **返回结果**: 最终，返回一段结构化、内容丰富的、由 AI 生成的主持人发言。

### 4. **单例模式**

- 为了提高效率和避免资源浪费，代码中使用了一个 `get_forum_host()` 函数来获取 `ForumHost` 的实例。
- 这个函数确保了在整个应用程序的生命周期中，`ForumHost` 类只会被实例化一次（即单例模式），这样就不需要每次都重新建立与 LLM 服务的连接。

### 总结

`llm_host.py` 是 `ForumEngine` 模块的大脑。它通过先进的 LLM 技术和精巧的提示词工程，将零散的、来自不同 Agent 的分析片段，整合成一个连贯、深入的分析讨论。它不仅是简单的总结，更是通过提出问题和新方向，主动引导整个舆情分析系统的“思考”过程，使其表现得更像一个协同工作的专家团队。
