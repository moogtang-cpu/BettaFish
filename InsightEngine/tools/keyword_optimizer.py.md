# tools/keyword_optimizer.py 文件分析

`InsightEngine/tools/keyword_optimizer.py` 文件定义了 `KeywordOptimizer` 类，这是一个在 `DeepSearchAgent` 工作流中扮演着至关重要“中间件”角色的工具。它的核心业务逻辑是**利用大语言模型（LLM）将 Agent 生成的、可能偏向于正式或学术风格的搜索查询，转化为更“接地气”、更适合在真实社交媒体舆情数据库中进行高效检索的关键词列表**。

### 1. **核心定位：搜索词转换与增强器**

-   `KeywordOptimizer` 并不直接执行搜索操作，而是作为 `DeepSearchAgent` 中搜索步骤前的一个关键预处理环节。它的存在旨在弥合 LLM 在生成高层级指令和实际数据库查询之间可能存在的“语言鸿沟”。Agent 生成的查询可能过于抽象，而舆情数据库的搜索需要更具体、更贴近用户实际表达的关键词。
-   其最终目标是显著提高搜索的相关性和召回率，确保 `DeepSearchAgent` 能够最大化地捕获到真实的民意和社交媒体上的原始讨论。

### 2. **`KeywordOptimizationResponse` 数据类**

-   该 `dataclass` 定义了关键词优化操作的标准化响应格式。它包含了原始查询 (`original_query`)、优化后的关键词列表 (`optimized_keywords`)、优化过程的理由 (`reasoning`)、操作是否成功 (`success`) 以及可能的错误信息 (`error_message`)。这种结构化的响应确保了优化的结果是清晰、可理解和可追溯的。

### 3. **初始化 (`__init__`)**

-   **配置驱动**：在创建 `KeywordOptimizer` 实例时，它会从项目的中央配置 (`settings`) 中加载用于关键词优化的 LLM 的 API 密钥 (`KEYWORD_OPTIMIZER_API_KEY`)、`base_url` 和 `model_name`（默认为 Qwen3 模型）。这种配置方式保证了系统的灵活性和可维护性。如果缺少必要的 API 密钥，程序会直接抛出 `ValueError`。
-   **封装 `OpenAI` 客户端**：在内部，它使用 `openai` 库的 `OpenAI` 客户端与外部的 LLM 服务进行通信，隐藏了底层的 API 调用细节。

### 4. **核心功能：`optimize_keywords` 方法**

-   **输入**：该方法接收 `original_query`（由 `DeepSearchAgent` 生成的初始搜索查询）以及可选的 `context`（额外的上下文信息，例如当前报告段落的标题或内容描述，这有助于 LLM 更准确地理解优化意图）。
-   **构建 Prompt**：
    -   **系统提示词 (`_build_system_prompt`)**：这是实现关键词优化的核心智能。它将 LLM 的角色设定为“专业的舆情数据挖掘专家”，并极其详细地定义了关键词优化的**核心原则**：
        -   **贴近网民语言**：强调使用普通网友在社交媒体上会使用的词汇。
        -   **避免专业术语**：明确列举了禁止使用的官方或学术词汇（如“舆情”、“传播”、“倾向”）。
        -   **简洁具体、情感丰富**：要求关键词简洁明了，并包含网民常用的情感表达词汇。
        -   **数量控制**：规定了关键词列表的数量范围（10到20个）。
        -   **格式要求**：**明确强调每个关键词都必须是一个不可分割的独立词条，严禁在词条内部包含空格。**
        -   提供了 JSON 输出格式的示例，并以此指导 LLM 的输出结构。
    -   **用户提示词 (`_build_user_prompt`)**：包含了原始查询和上下文信息，并再次强调了优化原则，确保 LLM 始终聚焦于任务目标。
-   **调用 LLM API (`_call_qwen_api`)**：
    -   将构建好的系统提示词和用户提示词发送给配置的 Qwen LLM。
    -   该调用被 `@with_graceful_retry` 装饰器包裹，提供了健壮的重试机制，增强了系统应对临时网络或服务故障的能力。
-   **解析与验证 LLM 响应**：
    -   **JSON 解析优先**：首先尝试将 LLM 返回的内容解析为 JSON 格式，从中提取 `keywords` 列表和 `reasoning`。
    -   **文本提取降级**：如果 LLM 返回的内容不是标准的 JSON 格式，则会触发 `_extract_keywords_from_text` 方法，尝试从纯文本中智能地提取出潜在的关键词。
    -   **关键词验证 (`_validate_keywords`)**：对所有提取到的关键词进行二次严格校验，过滤掉那些过于专业或官方的词汇，同时限制关键词的长度和总数量，确保最终产出的关键词质量高且符合舆情搜索的实际需求。
-   **容错与备用方案**：这是该工具健壮性的体现。如果在 LLM API 调用过程中发生失败、响应解析失败，或者关键词验证后未能得到任何有效关键词，它会触发一个**备用关键词提取方案** (`_fallback_keyword_extraction`)。这个方案会从原始查询中进行简单的词语分割和清理，确保即使在最坏情况下也能提供一组基础的搜索关键词，保证 `DeepSearchAgent` 的搜索流程能够继续执行，不会因关键词优化失败而中断。
-   **输出**：返回一个 `KeywordOptimizationResponse` 对象，其中包含了优化后的关键词列表、理由和操作状态。

### 5. **辅助方法**

-   `_extract_keywords_from_text`：在 LLM 返回非 JSON 格式时，尝试从纯文本中智能提取关键词，例如通过查找列表分隔符或引号内的内容。
-   `_validate_keywords`：用于对提取的关键词进行质量控制，清理和过滤不符合“贴近网民语言”原则的词汇，以及过长或不相关的词语。
-   `_fallback_keyword_extraction`：当 LLM 优化完全失败时的最终备用方案，它执行简单的基于分隔符的关键词分割，确保至少能有基本的搜索词可用。

### 6. **全局实例**

-   文件末尾创建了一个 `keyword_optimizer = KeywordOptimizer()` 的全局单例实例。这种设计使得 `InsightEngine` 的其他模块可以直接导入并使用这个优化器，而无需每次都重新实例化，提高了代码的便利性和资源效率。

### 总结

`InsightEngine/tools/keyword_optimizer.py` 是 `DeepSearchAgent` 实现**高质量、真实舆情数据检索**的关键“转化器”。它通过结合 LLM 强大的语义理解能力和一套严谨的关键词优化规则，将 Agent 生成的“高层意图”转化为舆情数据库能够高效匹配的“真实民意表达”。其强大的多层容错机制和备用方案，确保了关键词优化环节的健壮性，是 `DeepSearchAgent` 能够发现深层社会情绪和公众观点的核心技术支撑之一。
